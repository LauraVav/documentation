{
  "unversionedId": "Tool guides/tokenizer",
  "id": "version-2.0/Tool guides/tokenizer",
  "isDocsHomePage": false,
  "title": "Tokenizer",
  "description": "A tokenizer is a tool founded on an algorithm based on a set of rules or on the learning of a manually-labelled corpus. It allows text to be broken down into words. Itâ€™s a morphological analysis.",
  "source": "@site/versioned_docs/version-2.0/Tool guides/tokenizer.md",
  "sourceDirName": "Tool guides",
  "slug": "/Tool guides/tokenizer",
  "permalink": "/documentation/docs/Tool guides/tokenizer",
  "tags": [],
  "version": "2.0",
  "sidebarPosition": 1,
  "frontMatter": {
    "sidebar_position": 1
  },
  "sidebar": "version-2.0/tutorialSidebar",
  "previous": {
    "title": "Categories",
    "permalink": "/documentation/docs/API/Glossary/categories"
  },
  "next": {
    "title": "Lemmatizer",
    "permalink": "/documentation/docs/Tool guides/lemmatizer"
  }
}