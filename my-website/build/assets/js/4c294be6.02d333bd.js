"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[7953],{3905:function(e,t,n){n.d(t,{Zo:function(){return p},kt:function(){return d}});var r=n(7294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function l(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function i(e,t){if(null==e)return{};var n,r,a=function(e,t){if(null==e)return{};var n,r,a={},o=Object.keys(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var s=r.createContext({}),u=function(e){var t=r.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):l(l({},t),e)),n},p=function(e){var t=u(e.components);return r.createElement(s.Provider,{value:t},e.children)},c={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},m=r.forwardRef((function(e,t){var n=e.components,a=e.mdxType,o=e.originalType,s=e.parentName,p=i(e,["components","mdxType","originalType","parentName"]),m=u(n),d=a,y=m["".concat(s,".").concat(d)]||m[d]||c[d]||o;return n?r.createElement(y,l(l({ref:t},p),{},{components:n})):r.createElement(y,l({ref:t},p))}));function d(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var o=n.length,l=new Array(o);l[0]=m;var i={};for(var s in t)hasOwnProperty.call(t,s)&&(i[s]=t[s]);i.originalType=e,i.mdxType="string"==typeof e?e:a,l[1]=i;for(var u=2;u<o;u++)l[u]=n[u];return r.createElement.apply(null,l)}return r.createElement.apply(null,n)}m.displayName="MDXCreateElement"},4770:function(e,t,n){n.r(t),n.d(t,{frontMatter:function(){return i},contentTitle:function(){return s},metadata:function(){return u},toc:function(){return p},default:function(){return m}});var r=n(7462),a=n(3366),o=(n(7294),n(3905)),l=["components"],i={sidebar_position:2},s="Lemmatizer",u={unversionedId:"Tutorials/lemmatizer",id:"Tutorials/lemmatizer",isDocsHomePage:!1,title:"Lemmatizer",description:"Video",source:"@site/docs/Tutorials/lemmatizer.md",sourceDirName:"Tutorials",slug:"/Tutorials/lemmatizer",permalink:"/docs/Tutorials/lemmatizer",tags:[],version:"current",sidebarPosition:2,frontMatter:{sidebar_position:2},sidebar:"tutorialSidebar",previous:{title:"POS Tagger",permalink:"/docs/Tutorials/pos-tagger"},next:{title:"Sentence Type",permalink:"/docs/Tutorials/sentence-type"}},p=[{value:"Video",id:"video",children:[],level:2},{value:"What\u2019s a lemmatizer?",id:"whats-a-lemmatizer",children:[],level:2},{value:"Importing the library &amp; your personal API key",id:"importing-the-library--your-personal-api-key",children:[],level:2},{value:"Adding your document",id:"adding-your-document",children:[],level:2},{value:"Extracting lemmas",id:"extracting-lemmas",children:[],level:2},{value:"Saving your results",id:"saving-your-results",children:[],level:2},{value:"Code set",id:"code-set",children:[],level:2}],c={toc:p};function m(e){var t=e.components,i=(0,a.Z)(e,l);return(0,o.kt)("wrapper",(0,r.Z)({},c,i,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"lemmatizer"},"Lemmatizer"),(0,o.kt)("h2",{id:"video"},"Video"),(0,o.kt)("p",null,(0,o.kt)("a",{parentName:"p",href:"https://youtu.be/8wqI7Wzoxkk"},(0,o.kt)("img",{alt:"Lemma Video",src:n(4379).Z}))),(0,o.kt)("h2",{id:"whats-a-lemmatizer"},"What\u2019s a lemmatizer?"),(0,o.kt)("p",null,"Lemmatization is a tool of computational linguistics that does the work of ",(0,o.kt)("strong",{parentName:"p"},"extracting the lexical roots of words.")," It does not rely on sentence construction but on the lexicon, bringing out the root form of the word without inflection (no \u201cs\u201d for plural or other suffixes, for example)."),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"What does it do? How does it work?")),(0,o.kt)("h2",{id:"importing-the-library--your-personal-api-key"},"Importing the library & your personal API key"),(0,o.kt)("p",null,"If you want to extract the lexical roots of words you can use the lemmatization tool."),(0,o.kt)("p",null,"First you\u2019ll need to have your document saved to your computer and the Lettria SDK installed."),(0,o.kt)("p",null,"First I am going to import the Lettria library."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"Import lettria\n")),(0,o.kt)("p",null,"Next, add your personal API key to the nlp."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"api_key = \u2018api_key\u2019\nnlp = lettria.NLP(api_key)\n")),(0,o.kt)("h2",{id:"adding-your-document"},"Adding your document"),(0,o.kt)("p",null,"Next you'll need to add your document."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'with open("example.txt", "r") as f:\n    example_data = f.readlines()\n\nnlp.add_document(example_data)\n')),(0,o.kt)("h2",{id:"extracting-lemmas"},"Extracting lemmas"),(0,o.kt)("p",null,"In order to extract the lemma for each token in a sentences you can print the following command."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"print([s.lemma for s in nlp.sentences])\n")),(0,o.kt)("h2",{id:"saving-your-results"},"Saving your results"),(0,o.kt)("p",null,"In order to save your results you can use the following command."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"nlp.save_results(\u2018example_results')\n")),(0,o.kt)("p",null,"And a json file with you results that can be used for further analysis will be saved."),(0,o.kt)("h2",{id:"code-set"},"Code set"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'Import lettria\n\napi_key = \u2018api_key\u2019\nnlp = lettria.NLP(api_key)\n\nwith open("example.txt", "r") as f:\n    example_data = f.readlines()\n\nnlp.add_document(example_data)\n\nprint([s.lemma for s in nlp.sentences])\n\nnlp.save_results(\u2018example_results\')\n')),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"api-key",src:n(7248).Z})))}m.isMDXComponent=!0},7248:function(e,t,n){t.Z=n.p+"assets/images/api-key-ce2f1ec398eabc4030d2adca4788c541.png"},4379:function(e,t,n){t.Z=n.p+"assets/images/lemma-thumbnail-320be27df4abd5a91346999d959b6c4b.png"}}]);