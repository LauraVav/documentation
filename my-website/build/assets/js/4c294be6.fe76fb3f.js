"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[7953],{3905:function(e,t,n){n.d(t,{Zo:function(){return p},kt:function(){return d}});var r=n(7294);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function a(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function l(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?a(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):a(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function i(e,t){if(null==e)return{};var n,r,o=function(e,t){if(null==e)return{};var n,r,o={},a=Object.keys(e);for(r=0;r<a.length;r++)n=a[r],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(r=0;r<a.length;r++)n=a[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var s=r.createContext({}),u=function(e){var t=r.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):l(l({},t),e)),n},p=function(e){var t=u(e.components);return r.createElement(s.Provider,{value:t},e.children)},m={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},c=r.forwardRef((function(e,t){var n=e.components,o=e.mdxType,a=e.originalType,s=e.parentName,p=i(e,["components","mdxType","originalType","parentName"]),c=u(n),d=o,f=c["".concat(s,".").concat(d)]||c[d]||m[d]||a;return n?r.createElement(f,l(l({ref:t},p),{},{components:n})):r.createElement(f,l({ref:t},p))}));function d(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var a=n.length,l=new Array(a);l[0]=c;var i={};for(var s in t)hasOwnProperty.call(t,s)&&(i[s]=t[s]);i.originalType=e,i.mdxType="string"==typeof e?e:o,l[1]=i;for(var u=2;u<a;u++)l[u]=n[u];return r.createElement.apply(null,l)}return r.createElement.apply(null,n)}c.displayName="MDXCreateElement"},4770:function(e,t,n){n.r(t),n.d(t,{frontMatter:function(){return i},contentTitle:function(){return s},metadata:function(){return u},toc:function(){return p},default:function(){return c}});var r=n(7462),o=n(3366),a=(n(7294),n(3905)),l=["components"],i={sidebar_position:2},s="Lemmatizer",u={unversionedId:"Tutorials/lemmatizer",id:"Tutorials/lemmatizer",isDocsHomePage:!1,title:"Lemmatizer",description:"Video",source:"@site/docs/Tutorials/lemmatizer.md",sourceDirName:"Tutorials",slug:"/Tutorials/lemmatizer",permalink:"/docs/Tutorials/lemmatizer",tags:[],version:"current",sidebarPosition:2,frontMatter:{sidebar_position:2},sidebar:"tutorialSidebar",previous:{title:"POS tagger",permalink:"/docs/Tutorials/pos-tagger"},next:{title:"Sentence type",permalink:"/docs/Tutorials/sentence-type"}},p=[{value:"Video",id:"video",children:[],level:2},{value:"What does it do? How does it work?",id:"what-does-it-do-how-does-it-work",children:[{value:"Example:",id:"example",children:[],level:3}],level:2},{value:"Tutorial",id:"tutorial",children:[],level:2},{value:"Code set",id:"code-set",children:[],level:2}],m={toc:p};function c(e){var t=e.components,i=(0,o.Z)(e,l);return(0,a.kt)("wrapper",(0,r.Z)({},m,i,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"lemmatizer"},"Lemmatizer"),(0,a.kt)("h2",{id:"video"},"Video"),(0,a.kt)("p",null,(0,a.kt)("a",{parentName:"p",href:"https://youtu.be/hkvzQUJ7HM8"},(0,a.kt)("img",{alt:"Lemma Video",src:n(4379).Z}))),(0,a.kt)("p",null,"Lemmatization is a tool of computational linguistics that does the work of ",(0,a.kt)("strong",{parentName:"p"},"extracting the lexical roots of words.")," It does not rely on sentence construction but on the lexicon, bringing out the root form of the word without inflection (no \u201cs\u201d for plural or other suffixes, for example)."),(0,a.kt)("h2",{id:"what-does-it-do-how-does-it-work"},"What does it do? How does it work?"),(0,a.kt)("p",null,"A lemma should:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"reveal the generic form of the word"),(0,a.kt)("li",{parentName:"ul"},"make it possible to establish a lexical network in a document")),(0,a.kt)("h3",{id:"example"},"Example:"),(0,a.kt)("p",null,'The lemma of the common noun "horses" is "horse." The lemma of the conjugated verb "ate" is "eat."'),(0,a.kt)("p",null,"In Natural Language Processing (NLP), lemmatization makes possible the recognition of words as they\u2019re listed in the dictionary. It removes marks related to number or conjugation, resetting all verbs to the infinitive and reducing the phenomenon of derivation (which means, adding an affix that changes the sense of the word, like im-possible)."),(0,a.kt)("p",null,"Lemmatization allows us to identify the ",(0,a.kt)("strong",{parentName:"p"},"primary and generic form of words.")," Contrary to the stem that appears without affix and leaves the word unrecognizable, the lemma is content to return to its generic form. At Lettria, nous we privilege the use of lemmas over stems."),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"Example:")),(0,a.kt)("p",null,"The stem of the common noun \u201cmountain\u201d is \u201cmount,\u201d and its lemma is \u201cmountain.\u201d"),(0,a.kt)("h2",{id:"tutorial"},"Tutorial"),(0,a.kt)("p",null,"If you want to extract the lexical roots of words you can use the lemmatization tool."),(0,a.kt)("p",null,"First you\u2019ll need to have your document saved to your computer and the Lettria SDK installed."),(0,a.kt)("p",null,"First I am going to import the Lettria library."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"Import lettria\n")),(0,a.kt)("p",null,"Next, add your personal API key to the nlp."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"api_key = \u2018api_key\u2019\nnlp = lettria.NLP(api_key)\n")),(0,a.kt)("p",null,"Next you'll need to add your document."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'with open("example.txt", "r") as f:\n    example_data = f.readlines()\n\nnlp.add_document(example_data)\n')),(0,a.kt)("p",null,"In order to extract the lemma for each token in a sentences you can print the following command."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"print([s.lemma for s in nlp.sentences])\n")),(0,a.kt)("p",null,"In order to save your results you can use the following command."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"nlp.save_results(\u2018example_results')\n")),(0,a.kt)("p",null,"And a json file with you results that can be used for further analysis will be saved."),(0,a.kt)("h2",{id:"code-set"},"Code set"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'Import lettria\n\napi_key = \u2018api_key\u2019\nnlp = lettria.NLP(api_key)\n\nwith open("example.txt", "r") as f:\n    example_data = f.readlines()\n\nnlp.add_document(example_data)\n\nprint([s.lemma for s in nlp.sentences])\n\nnlp.save_results(\u2018example_results\')\n')))}c.isMDXComponent=!0},4379:function(e,t,n){t.Z=n.p+"assets/images/lemma-thumbnail-320be27df4abd5a91346999d959b6c4b.png"}}]);